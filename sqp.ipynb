{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import NonlinearConstraint, minimize, LinearConstraint\n",
    "import numpy as np\n",
    "from scipy.special import gamma, factorial\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_list = [0.45, 0.5, 0.55]\n",
    "delta_list = np.arange(0.55, 1.0, 0.05)\n",
    "\n",
    "sqp_dict = {}\n",
    "N = 50\n",
    "T = 1\n",
    "X = 0.1\n",
    "for delta_const in delta_list:\n",
    "    for gamma_const in gamma_list:\n",
    "        sqp_dict[(delta_const, gamma_const)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-b8b63946fc93>:6: RuntimeWarning: invalid value encountered in power\n",
      "  * ((i - j + 1) ** (2 - gamma_const) - 2 * (i - j) ** (2 - gamma_const) +\\\n",
      "<ipython-input-19-b8b63946fc93>:7: RuntimeWarning: invalid value encountered in power\n",
      "  (i - j - 1) ** (2 - gamma_const))\n",
      "<ipython-input-19-b8b63946fc93>:24: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return (c / (t * (T - t)) ** ((1 - gamma_const) / 2))\n"
     ]
    }
   ],
   "source": [
    "for (delta_const, gamma_const) in sqp_dict:\n",
    "    G = np.zeros((N, N))\n",
    "\n",
    "    def G_ij_upper(i, j):\n",
    "        return (1 / (1 - gamma_const) * (1 - gamma_const)) * (T / N) ** (2 - gamma_const) \\\n",
    "                * ((i - j + 1) ** (2 - gamma_const) - 2 * (i - j) ** (2 - gamma_const) +\\\n",
    "                    (i - j - 1) ** (2 - gamma_const)) \n",
    "\n",
    "    def G_ii_diagonal():\n",
    "        return (2 / ((1 - gamma_const) * (2 - gamma_const))) * (T / N) ** (2 - gamma_const)\n",
    "        \n",
    "    G_upper = np.fromfunction(G_ij_upper, (N, N))\n",
    "    G_upper = np.nan_to_num(G_upper, nan = 0.0)\n",
    "    G_diag = np.repeat(G_ii_diagonal(), N)\n",
    "    G_diag = np.diag(G_diag)\n",
    "    G = G_upper.T + G_upper + G_diag\n",
    "\n",
    "    v_guess = np.repeat(T * X / N, N) ## VWAP\n",
    "\n",
    "    def gss_guess(t: np.array) -> np.array:\n",
    "        gamma_1 = gamma((1 + gamma_const)/ 2)\n",
    "        gamma_2 = gamma(1 + (gamma_const / 2))\n",
    "        c = (X / N) / (np.sqrt(np.pi) * (T / 2) ** gamma_const * (gamma_1 / gamma_2))\n",
    "        return (c / (t * (T - t)) ** ((1 - gamma_const) / 2))\n",
    "    gss_v_0_guess = gss_guess(np.arange(0, 1 + 1 / (N + 1), 1 / (N + 1)))[1:-1]\n",
    "    def impact_f(v):\n",
    "        return np.sign(v) * np.abs(v) ** delta_const\n",
    "\n",
    "    A = G_upper + G_diag / 2\n",
    "\n",
    "    def expect_cost_compute(v):\n",
    "        return v @ A @ impact_f(v).T\n",
    "    \n",
    "    def total_volume_cons(x):\n",
    "        return np.sum(x) - N * X / T\n",
    "    \n",
    "    cons = {'type':'eq', 'fun': total_volume_cons}\n",
    "    result_gss = minimize(expect_cost_compute, gss_v_0_guess, method = \"SLSQP\", constraints=cons, options = {\"maxiter\" : 1000})\n",
    "    sqp_dict[(delta_const, gamma_const)] = result_gss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0.55,\n",
       "  0.45):      fun: 0.01013606575767331\n",
       "      jac: array([0.00315152, 0.00318823, 0.00318062, 0.00298958, 0.00306942,\n",
       "        0.0033133 , 0.00252477, 0.00327525, 0.0032034 , 0.00307297,\n",
       "        0.00309484, 0.00329416, 0.00328105, 0.00310307, 0.00310579,\n",
       "        0.00306825, 0.00329323, 0.00323004, 0.00321481, 0.00305094,\n",
       "        0.00332419, 0.00301963, 0.00310438, 0.00313437, 0.00329864,\n",
       "        0.00298353, 0.00318894, 0.0028844 , 0.00322949, 0.00308417,\n",
       "        0.00315693, 0.00317009, 0.00316566, 0.00307483, 0.00301733,\n",
       "        0.0031578 , 0.00320032, 0.00329231, 0.00323805, 0.00307929,\n",
       "        0.00327919, 0.0029693 , 0.00309455, 0.0031971 , 0.00310012,\n",
       "        0.00313656, 0.00308223, 0.00303779, 0.00326411, 0.0031106 ])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 12445\n",
       "      nit: 243\n",
       "     njev: 243\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([-0.04926557, -0.04356815, -0.04229077, -0.04563001, -0.04454471,\n",
       "        -0.04132617, -0.05924094, -0.04685064, -0.05268008, -0.06244334,\n",
       "        -0.07575688, -0.11656616,  1.43616987, -0.05386275, -0.03572622,\n",
       "        -0.03342846, -0.02979567, -0.03070633, -0.03143456, -0.03445894,\n",
       "        -0.03238969, -0.03798143, -0.03908431, -0.04168155, -0.04322899,\n",
       "        -0.05375641, -0.05876649, -0.08180716, -0.12786628,  1.79226429,\n",
       "        -0.04484236, -0.03071461, -0.02931815, -0.03082371, -0.03301819,\n",
       "        -0.03373078, -0.03652772, -0.03982515, -0.0468724 , -0.05955294,\n",
       "        -0.07375566, -0.14301899,  1.81504893, -0.07445529, -0.09506261,\n",
       "         1.15106095, -0.06657387,  0.60634334,  0.24413072,  0.23921298]),\n",
       " (0.55,\n",
       "  0.5):      fun: 0.026045274291456626\n",
       "      jac: array([0.00790932, 0.00836112, 0.00820496, 0.00806748, 0.00799097,\n",
       "        0.00796225, 0.00796123, 0.0079748 , 0.00799296, 0.00800684,\n",
       "        0.00801417, 0.00802086, 0.0080336 , 0.00805352, 0.00807695,\n",
       "        0.00809928, 0.00811782, 0.00813278, 0.00814614, 0.00815829,\n",
       "        0.00816537, 0.00816298, 0.00815298, 0.00814172, 0.00813269,\n",
       "        0.00812475, 0.00811514, 0.00810198, 0.00808504, 0.00806551,\n",
       "        0.00804527, 0.00802629, 0.00800994, 0.00799675, 0.00798636,\n",
       "        0.0079782 , 0.00797215, 0.00796909, 0.00797074, 0.00797897,\n",
       "        0.00799498, 0.0080189 , 0.00804957, 0.00808477, 0.00812138,\n",
       "        0.00815549, 0.00818251, 0.00819725, 0.00820201, 0.00819998])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 1377\n",
       "      nit: 27\n",
       "     njev: 27\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([1.09543111, 0.49580213, 0.29030499, 0.18802924, 0.13349705,\n",
       "        0.10337927, 0.08619566, 0.07622331, 0.0708979 , 0.06917054,\n",
       "        0.07030252, 0.07325842, 0.07674406, 0.07954723, 0.08079232,\n",
       "        0.08001943, 0.07718065, 0.07265292, 0.06726111, 0.06220051,\n",
       "        0.05867229, 0.05727163, 0.0576507 , 0.05879718, 0.05965934,\n",
       "        0.05957704, 0.05833684, 0.05604884, 0.05299761, 0.04952371,\n",
       "        0.04596173, 0.04260476, 0.03969502, 0.03741796, 0.03590937,\n",
       "        0.03525342, 0.03548706, 0.03660399, 0.0385594 , 0.04127881,\n",
       "        0.04466559, 0.04860948, 0.0529944 , 0.05770505, 0.06263789,\n",
       "        0.06771656, 0.07293417, 0.07850079, 0.0849301 , 0.1231089 ]),\n",
       " (0.55,\n",
       "  0.55):      fun: 0.028617024788481372\n",
       "      jac: array([0.00877887, 0.00903781, 0.00893171, 0.00885428, 0.00880942,\n",
       "        0.00878879, 0.00878413, 0.00878969, 0.00880166, 0.00881746,\n",
       "        0.00883521, 0.00885349, 0.00887114, 0.00888722, 0.008901  ,\n",
       "        0.00891199, 0.00891989, 0.00892458, 0.00892612, 0.00892468,\n",
       "        0.00892054, 0.00891401, 0.0089055 , 0.00889543, 0.00888425,\n",
       "        0.00887242, 0.00886043, 0.00884875, 0.00883783, 0.00882809,\n",
       "        0.00881993, 0.0088137 , 0.00880969, 0.00880815, 0.00880927,\n",
       "        0.00881319, 0.00881995, 0.00882952, 0.00884175, 0.00885638,\n",
       "        0.00887298, 0.00889096, 0.00890953, 0.00892762, 0.00894386,\n",
       "        0.00895643, 0.00896296, 0.00896034, 0.00894846, 0.00893983])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 1377\n",
       "      nit: 27\n",
       "     njev: 27\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.70366171, 0.35448125, 0.24087996, 0.18230345, 0.14869005,\n",
       "        0.12811495, 0.11491399, 0.10611536, 0.10005097, 0.0957241 ,\n",
       "        0.09250035, 0.08995479, 0.08779721, 0.08583358, 0.08394145,\n",
       "        0.08205197, 0.08013392, 0.07818056, 0.07619876, 0.07420197,\n",
       "        0.0722063 , 0.07022853, 0.06828582, 0.06639732, 0.06458346,\n",
       "        0.06286708, 0.0612727 , 0.05982556, 0.05855054, 0.0574715 ,\n",
       "        0.05660955, 0.05598294, 0.05560655, 0.05549116, 0.05564429,\n",
       "        0.05606963, 0.05676837, 0.05773919, 0.05897934, 0.06048561,\n",
       "        0.06225529, 0.06428848, 0.06658998, 0.06917445, 0.07207521,\n",
       "        0.07536472, 0.07920682, 0.0840169 , 0.09070063, 0.11953171]),\n",
       " (0.6000000000000001,\n",
       "  0.45):      fun: 0.012825127620365381\n",
       "      jac: array([0.00417313, 0.00400335, 0.00409445, 0.00415763, 0.00415604,\n",
       "        0.00417089, 0.00407779, 0.00389657, 0.00409891, 0.00416654,\n",
       "        0.00398073, 0.00412614, 0.00402926, 0.0041088 , 0.00400568,\n",
       "        0.00414828, 0.0039826 , 0.00424164, 0.00421433, 0.00417911,\n",
       "        0.0040063 , 0.00411869, 0.00403773, 0.00405496, 0.00406648,\n",
       "        0.00413763, 0.00409334, 0.00416899, 0.00407   , 0.00408281,\n",
       "        0.00407193, 0.00420025, 0.00384984, 0.00406359, 0.00395235,\n",
       "        0.00394166, 0.00434048, 0.00429357, 0.004098  , 0.00401473,\n",
       "        0.00396911, 0.00405005, 0.0042224 , 0.00414164, 0.00402968,\n",
       "        0.00411378, 0.00421693, 0.00398304, 0.00410641, 0.00409977])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 10604\n",
       "      nit: 207\n",
       "     njev: 207\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([ 0.44183037, -0.06287881, -0.04380006, -0.0409997 , -0.04226051,\n",
       "        -0.04607693, -0.05455914, -0.09094758,  0.932688  , -0.04234321,\n",
       "        -0.03251552, -0.02729638, -0.027945  , -0.02837363, -0.02826167,\n",
       "        -0.02885704, -0.03143508, -0.02986685, -0.03228793, -0.03524604,\n",
       "        -0.04155   , -0.04386633, -0.0531032 , -0.06723036, -0.11170575,\n",
       "         1.30725691, -0.06538427, -0.05059861, -0.05857   , -0.09291407,\n",
       "         0.98158454, -0.06504556, -0.08485449,  0.75356166, -0.04907588,\n",
       "        -0.03826303, -0.03674024, -0.06331881,  0.80874625, -0.0456564 ,\n",
       "        -0.05567971,  0.57927478,  0.14273039, -0.03579575,  0.35534945,\n",
       "         0.0363839 ,  0.02718662,  0.13551575,  0.11998972,  0.16320521]),\n",
       " (0.6000000000000001,\n",
       "  0.5):      fun: 0.02403358886909695\n",
       "      jac: array([0.00757996, 0.00789485, 0.0077697 , 0.0076805 , 0.00763245,\n",
       "        0.00761155, 0.00760627, 0.00761   , 0.00761893, 0.00763092,\n",
       "        0.00764507, 0.00766104, 0.00767841, 0.00769631, 0.0077136 ,\n",
       "        0.0077291 , 0.0077419 , 0.0077514 , 0.00775732, 0.0077596 ,\n",
       "        0.00775841, 0.00775398, 0.00774662, 0.00773668, 0.00772457,\n",
       "        0.00771079, 0.0076959 , 0.00768056, 0.0076654 , 0.00765107,\n",
       "        0.00763811, 0.00762696, 0.00761801, 0.00761158, 0.00760799,\n",
       "        0.00760755, 0.00761059, 0.00761736, 0.007628  , 0.00764242,\n",
       "        0.00766025, 0.00768079, 0.00770296, 0.0077253 , 0.00774595,\n",
       "        0.00776263, 0.00777274, 0.00777389, 0.00777139, 0.00777147])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 1326\n",
       "      nit: 26\n",
       "     njev: 26\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.86795388, 0.39936513, 0.24843373, 0.17434242, 0.13448029,\n",
       "        0.11182441, 0.09842994, 0.09036216, 0.0855991 , 0.08299568,\n",
       "        0.08176632, 0.08128701, 0.08105772, 0.08072606, 0.08009572,\n",
       "        0.07910719, 0.07780122, 0.07626691, 0.07459488, 0.07284933,\n",
       "        0.07105183, 0.06918966, 0.06723794, 0.06517574, 0.06300431,\n",
       "        0.06075301, 0.05847403, 0.05623875, 0.05412817, 0.05222346,\n",
       "        0.05060177, 0.04932963, 0.04846175, 0.04803837, 0.04808601,\n",
       "        0.04861679, 0.04963048, 0.05111571, 0.05305128, 0.05540876,\n",
       "        0.05815375, 0.06124865, 0.06465499, 0.06833858, 0.07228048,\n",
       "        0.07650445, 0.08115347, 0.08674404, 0.09474023, 0.13702483]),\n",
       " (0.6000000000000001,\n",
       "  0.55):      fun: 0.0260184324299458\n",
       "      jac: array([0.00814779, 0.00853736, 0.00851171, 0.00845061, 0.00839051,\n",
       "        0.00834115, 0.00830405, 0.00827811, 0.00826158, 0.00825271,\n",
       "        0.00824999, 0.00825218, 0.00825824, 0.00826729, 0.00827861,\n",
       "        0.00829154, 0.00830551, 0.00832003, 0.00833462, 0.00834888,\n",
       "        0.00836244, 0.00837497, 0.00838617, 0.00839579, 0.00840364,\n",
       "        0.00840955, 0.0084134 , 0.00841513, 0.00841469, 0.00841211,\n",
       "        0.00840743, 0.00840074, 0.00839214, 0.00838178, 0.00836981,\n",
       "        0.00835641, 0.00834178, 0.00832614, 0.00830969, 0.00829269,\n",
       "        0.00827541, 0.00825814, 0.00824128, 0.00822528, 0.00821086,\n",
       "        0.00819909, 0.00819184, 0.00819283, 0.00821279, 0.00825664])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 1020\n",
       "      nit: 20\n",
       "     njev: 20\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.51826824, 0.31565175, 0.23489921, 0.1870649 , 0.15578577,\n",
       "        0.13425582, 0.11897433, 0.10790817, 0.09978208, 0.09375388,\n",
       "        0.08924711, 0.08585706, 0.08329418, 0.08134812, 0.07986384,\n",
       "        0.07872531, 0.07784427, 0.07715223, 0.07659517, 0.0761299 ,\n",
       "        0.07572173, 0.07534283, 0.07497139, 0.07459075, 0.07418913,\n",
       "        0.073759  , 0.07329675, 0.07280229, 0.07227854, 0.07173125,\n",
       "        0.07116826, 0.07059966, 0.07003713, 0.06949392, 0.06898484,\n",
       "        0.06852616, 0.06813599, 0.06783459, 0.06764539, 0.06759628,\n",
       "        0.06772175, 0.06806693, 0.06869387, 0.06969333, 0.07120739,\n",
       "        0.07347624, 0.07694805, 0.08258257, 0.09287733, 0.12762534]),\n",
       " (0.6500000000000001,\n",
       "  0.45):      fun: 0.020532738224703\n",
       "      jac: array([0.00666636, 0.00698196, 0.00682525, 0.0067397 , 0.00671452,\n",
       "        0.006716  , 0.00672457, 0.00673074, 0.00672826, 0.00671793,\n",
       "        0.00670824, 0.00670732, 0.00671731, 0.00673581, 0.00675939,\n",
       "        0.00678547, 0.00681183, 0.00683481, 0.00684994, 0.00685559,\n",
       "        0.00685515, 0.00685346, 0.00685247, 0.00685107, 0.00684702,\n",
       "        0.00683875, 0.00682597, 0.00680955, 0.00679114, 0.00677258,\n",
       "        0.00675546, 0.00674072, 0.00672843, 0.00671801, 0.00670874,\n",
       "        0.00670044, 0.00669384, 0.00669042, 0.00669181, 0.00669916,\n",
       "        0.00671279, 0.00673205, 0.00675551, 0.00678109, 0.00680631,\n",
       "        0.0068285 , 0.00684517, 0.00685492, 0.00686732, 0.00687036])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 1479\n",
       "      nit: 29\n",
       "     njev: 29\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([1.06800546, 0.4313668 , 0.23550383, 0.14706472, 0.10437291,\n",
       "        0.08297047, 0.07204996, 0.06702293, 0.06606633, 0.06810705,\n",
       "        0.07187952, 0.07589801, 0.07883259, 0.07983508, 0.0786832 ,\n",
       "        0.07579062, 0.07210879, 0.06888479, 0.06716831, 0.06733264,\n",
       "        0.06890813, 0.07090404, 0.07233292, 0.07254394, 0.07130965,\n",
       "        0.06872964, 0.06509901, 0.06080005, 0.05621804, 0.0517096 ,\n",
       "        0.04757427, 0.04405395, 0.04133032, 0.03952991, 0.03872427,\n",
       "        0.0389348 , 0.0401344 , 0.04225906, 0.0452133 , 0.04888276,\n",
       "        0.05313774, 0.05784223, 0.06286043, 0.06807146, 0.07339171,\n",
       "        0.07882168, 0.08455171, 0.09132625, 0.10157633, 0.16428437]),\n",
       " (0.6500000000000001,\n",
       "  0.5):      fun: 0.02199823813566739\n",
       "      jac: array([0.00705291, 0.00750635, 0.00748855, 0.00742132, 0.00735256,\n",
       "        0.00729542, 0.00725204, 0.00722091, 0.00719969, 0.00718625,\n",
       "        0.00717897, 0.0071767 , 0.00717858, 0.00718395, 0.00719223,\n",
       "        0.00720292, 0.00721553, 0.00722961, 0.00724471, 0.0072604 ,\n",
       "        0.00727623, 0.00729176, 0.00730653, 0.00732011, 0.0073321 ,\n",
       "        0.00734215, 0.00734992, 0.0073552 , 0.00735778, 0.00735758,\n",
       "        0.00735454, 0.00734868, 0.00734008, 0.00732887, 0.00731521,\n",
       "        0.00729933, 0.00728148, 0.00726194, 0.00724105, 0.00721919,\n",
       "        0.0071968 , 0.00717442, 0.00715271, 0.00713257, 0.00711519,\n",
       "        0.00710234, 0.00709684, 0.00710358, 0.00713437, 0.00717545])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 970\n",
       "      nit: 19\n",
       "     njev: 19\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.60599856, 0.35683112, 0.25463566, 0.19436867, 0.15545008,\n",
       "        0.12916502, 0.11096844, 0.09819473, 0.0891627 , 0.08276132,\n",
       "        0.07823455, 0.07505952, 0.07287123, 0.07141381, 0.07050556,\n",
       "        0.07001521, 0.06984359, 0.06991175, 0.07015272, 0.07050732,\n",
       "        0.07092222, 0.07134965, 0.07174803, 0.07208274, 0.07232701,\n",
       "        0.07246147, 0.07247466, 0.0723622 , 0.07212572, 0.07177263,\n",
       "        0.07131434, 0.07076628, 0.07014647, 0.06947527, 0.0687751 ,\n",
       "        0.06806998, 0.06738628, 0.06675298, 0.06620356, 0.06577753,\n",
       "        0.06552478, 0.06551106, 0.06582834, 0.06661295, 0.06807931,\n",
       "        0.07059105, 0.07482355, 0.08220993, 0.09647216, 0.14400116]),\n",
       " (0.6500000000000001,\n",
       "  0.55):      fun: 0.023502467119425063\n",
       "      jac: array([0.00764371, 0.00793026, 0.00790304, 0.00785697, 0.00781441,\n",
       "        0.00778055, 0.00775569, 0.00773876, 0.00772842, 0.00772341,\n",
       "        0.00772261, 0.00772508, 0.00773002, 0.00773674, 0.00774466,\n",
       "        0.00775328, 0.00776217, 0.00777097, 0.00777934, 0.00778704,\n",
       "        0.00779385, 0.00779958, 0.00780411, 0.00780733, 0.00780917,\n",
       "        0.00780962, 0.00780866, 0.00780632, 0.00780264, 0.00779769,\n",
       "        0.00779155, 0.00778432, 0.00777611, 0.00776702, 0.0077572 ,\n",
       "        0.00774675, 0.00773582, 0.00772454, 0.00771306, 0.00770153,\n",
       "        0.00769012, 0.00767903, 0.00766852, 0.00765894, 0.00765086,\n",
       "        0.00764514, 0.00764337, 0.00764868, 0.00766987, 0.0077049 ])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 970\n",
       "      nit: 19\n",
       "     njev: 19\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.42537351, 0.26648108, 0.20471447, 0.16835844, 0.1445984 ,\n",
       "        0.12817099, 0.11640552, 0.10777085, 0.10131796, 0.09642604,\n",
       "        0.09267261, 0.08976152, 0.08748006, 0.08567242, 0.08422251,\n",
       "        0.08304261, 0.08206567, 0.08124003, 0.08052569, 0.07989184,\n",
       "        0.07931489, 0.07877712, 0.07826563, 0.07777155, 0.07728941,\n",
       "        0.07681656, 0.07635272, 0.07589975, 0.07546111, 0.07504179,\n",
       "        0.07464802, 0.07428725, 0.07396788, 0.07369956, 0.073493  ,\n",
       "        0.07336036, 0.07331556, 0.07337501, 0.07355849, 0.07389068,\n",
       "        0.07440379, 0.07514143, 0.07616576, 0.07756962, 0.07950024,\n",
       "        0.08220785, 0.08615842, 0.09234318, 0.10333369, 0.13839746]),\n",
       " (0.7000000000000002,\n",
       "  0.45):      fun: 0.01894402115800038\n",
       "      jac: array([0.00620048, 0.00668405, 0.00667303, 0.00660434, 0.00653389,\n",
       "        0.00647697, 0.00643543, 0.00640656, 0.0063868 , 0.00637337,\n",
       "        0.00636461, 0.00635972, 0.0063583 , 0.00636011, 0.00636485,\n",
       "        0.0063722 , 0.00638189, 0.00639365, 0.00640726, 0.0064225 ,\n",
       "        0.00643903, 0.00645644, 0.0064742 , 0.00649169, 0.00650826,\n",
       "        0.00652328, 0.00653617, 0.00654643, 0.00655367, 0.0065576 ,\n",
       "        0.00655806, 0.00655498, 0.00654836, 0.00653833, 0.00652504,\n",
       "        0.00650876, 0.00648978, 0.00646847, 0.00644527, 0.0064207 ,\n",
       "        0.00639536, 0.00637   , 0.00634551, 0.00632305, 0.00630413,\n",
       "        0.00629085, 0.00628633, 0.00629558, 0.0063288 , 0.00635297])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 969\n",
       "      nit: 19\n",
       "     njev: 19\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.69770005, 0.39814213, 0.27225488, 0.19851346, 0.15160492,\n",
       "        0.12061312, 0.09976717, 0.08565138, 0.07610029, 0.06968278,\n",
       "        0.06543408, 0.06270193, 0.0610522 , 0.06020261, 0.05997321,\n",
       "        0.06024716, 0.06094068, 0.06198074, 0.06329229, 0.06479336,\n",
       "        0.06639636, 0.06801256, 0.06955849, 0.07096113, 0.07216157,\n",
       "        0.07311751, 0.07380174, 0.0742025 , 0.07432078, 0.07416779,\n",
       "        0.07376331, 0.07313297, 0.07230628, 0.07131619, 0.07019708,\n",
       "        0.06898535, 0.0677197 , 0.06644246, 0.06520214, 0.06405729,\n",
       "        0.06308249, 0.06237752, 0.06208327, 0.06240796, 0.06367794,\n",
       "        0.06643991, 0.07169508, 0.0815301 , 0.10129585, 0.16493821]),\n",
       " (0.7000000000000002,\n",
       "  0.5):      fun: 0.019945452546897075\n",
       "      jac: array([0.00664044, 0.00697572, 0.00695304, 0.00690214, 0.00685311,\n",
       "        0.00681318, 0.00678306, 0.00676161, 0.00674739, 0.00673907,\n",
       "        0.00673556, 0.00673594, 0.00673946, 0.00674547, 0.0067534 ,\n",
       "        0.00676272, 0.00677296, 0.00678369, 0.0067945 , 0.00680504,\n",
       "        0.00681495, 0.00682396, 0.00683181, 0.00683828, 0.00684321,\n",
       "        0.00684647, 0.00684797, 0.00684769, 0.0068456 , 0.00684174,\n",
       "        0.00683616, 0.00682894, 0.00682019, 0.00681003, 0.00679859,\n",
       "        0.00678603, 0.00677254, 0.00675828, 0.00674349, 0.00672841,\n",
       "        0.00671334, 0.00669863, 0.00668478, 0.00667242, 0.00666248,\n",
       "        0.00665638, 0.00665638, 0.00666642, 0.00669577, 0.00672502])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 1021\n",
       "      nit: 20\n",
       "     njev: 20\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.49360018, 0.29748761, 0.21927096, 0.17355702, 0.14411199,\n",
       "        0.12416575, 0.11024527, 0.10034756, 0.09322888, 0.08807796,\n",
       "        0.08434635, 0.08165321, 0.07972789, 0.07837377, 0.07744454,\n",
       "        0.07682911, 0.07644094, 0.07621153, 0.07608634, 0.0760214 ,\n",
       "        0.07598206, 0.07594127, 0.07587897, 0.07578112, 0.07563878,\n",
       "        0.07544768, 0.07520755, 0.07492136, 0.07459462, 0.07423548,\n",
       "        0.07385357, 0.07346028, 0.07306824, 0.0726914 , 0.07234503,\n",
       "        0.0720463 , 0.07181432, 0.07167174, 0.07164565, 0.07177057,\n",
       "        0.07209167, 0.07267144, 0.07359992, 0.07501345, 0.07712974,\n",
       "        0.08032023, 0.08527599, 0.09345786, 0.10864781, 0.15656763]),\n",
       " (0.7000000000000002,\n",
       "  0.55):      fun: 0.021164959169318993\n",
       "      jac: array([0.00687067, 0.00724764, 0.0073052 , 0.00730478, 0.00728313,\n",
       "        0.00725387, 0.00722306, 0.0071936 , 0.00716691, 0.00714365,\n",
       "        0.00712406, 0.00710816, 0.00709581, 0.00708682, 0.00708095,\n",
       "        0.00707796, 0.00707757, 0.00707952, 0.00708356, 0.00708943,\n",
       "        0.00709688, 0.00710568, 0.00711558, 0.00712638, 0.00713786,\n",
       "        0.00714981, 0.00716204, 0.00717438, 0.00718664, 0.00719868,\n",
       "        0.00721034, 0.0072215 , 0.00723204, 0.00724186, 0.00725089,\n",
       "        0.00725908, 0.00726639, 0.00727283, 0.00727843, 0.00728327,\n",
       "        0.0072875 , 0.0072913 , 0.00729496, 0.00729886, 0.0073035 ,\n",
       "        0.00730952, 0.00731768, 0.00732865, 0.0073423 , 0.00731159])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 613\n",
       "      nit: 12\n",
       "     njev: 12\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.31096672, 0.22956408, 0.19117566, 0.16572656, 0.14719541,\n",
       "        0.13302656, 0.12186871, 0.11291201, 0.10562953, 0.09965783,\n",
       "        0.09473495, 0.09066555, 0.08729991, 0.08452066, 0.08223406,\n",
       "        0.08036407, 0.0788482 , 0.07763453, 0.07667949, 0.07594631,\n",
       "        0.07540371, 0.07502497, 0.0747873 , 0.07467109, 0.07465963,\n",
       "        0.07473873, 0.07489636, 0.07512263, 0.07540952, 0.07575089,\n",
       "        0.07614237, 0.07658159, 0.07706805, 0.07760372, 0.0781929 ,\n",
       "        0.07884313, 0.07956564, 0.08037644, 0.08129779, 0.08236019,\n",
       "        0.08360574, 0.08509284, 0.08690424, 0.0891602 , 0.09204247,\n",
       "        0.09584121, 0.1010579 , 0.10867376, 0.12107489, 0.15139927]),\n",
       " (0.7500000000000002,\n",
       "  0.45):      fun: 0.017310933267788115\n",
       "      jac: array([0.00557028, 0.00607193, 0.00619309, 0.00622216, 0.00621205,\n",
       "        0.00618417, 0.00614896, 0.00611195, 0.0060762 , 0.00604332,\n",
       "        0.0060141 , 0.00598879, 0.00596738, 0.00594968, 0.00593543,\n",
       "        0.00592436, 0.00591621, 0.00591078, 0.00590787, 0.00590732,\n",
       "        0.005909  , 0.00591277, 0.00591848, 0.00592598, 0.00593514,\n",
       "        0.00594577, 0.0059577 , 0.00597077, 0.00598479, 0.00599958,\n",
       "        0.00601497, 0.0060308 , 0.00604692, 0.00606318, 0.00607947,\n",
       "        0.00609567, 0.0061117 , 0.0061275 , 0.00614303, 0.00615829,\n",
       "        0.00617331, 0.00618817, 0.00620299, 0.0062179 , 0.00623305,\n",
       "        0.00624844, 0.00626368, 0.006277  , 0.00628177, 0.00620761])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 561\n",
       "      nit: 11\n",
       "     njev: 11\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.41990034, 0.30333341, 0.24286066, 0.20150754, 0.1708802 ,\n",
       "        0.14725646, 0.12859908, 0.11365107, 0.10157365, 0.09177509,\n",
       "        0.08381978, 0.07737672, 0.07218742, 0.06804595, 0.06478534,\n",
       "        0.06226802, 0.06037953, 0.0590237 , 0.05811906, 0.05759614,\n",
       "        0.05739572, 0.05746706, 0.05776677, 0.05825778, 0.05890878,\n",
       "        0.05969326, 0.06058931, 0.06157895, 0.062648  , 0.0637854 ,\n",
       "        0.0649836 , 0.06623789, 0.06754687, 0.06891231, 0.07033999,\n",
       "        0.07184013, 0.07342887, 0.07512977, 0.07697664, 0.07901691,\n",
       "        0.08131738, 0.08397226, 0.08711622, 0.09094537, 0.09575496,\n",
       "        0.1020109 , 0.11050351, 0.12273735, 0.14223945, 0.18595946]),\n",
       " (0.7500000000000002,\n",
       "  0.5):      fun: 0.017993668796204336\n",
       "      jac: array([0.00620326, 0.00644565, 0.00642164, 0.00638226, 0.0063463 ,\n",
       "        0.00631781, 0.00629688, 0.00628255, 0.00627371, 0.00626933,\n",
       "        0.00626852, 0.00627051, 0.00627462, 0.00628029, 0.00628703,\n",
       "        0.00629439, 0.00630201, 0.00630956, 0.00631677, 0.00632341,\n",
       "        0.00632928, 0.00633425, 0.0063382 , 0.00634105, 0.00634274,\n",
       "        0.00634327, 0.00634262, 0.00634081, 0.00633789, 0.0063339 ,\n",
       "        0.00632891, 0.00632298, 0.0063162 , 0.00630865, 0.00630041,\n",
       "        0.0062916 , 0.0062823 , 0.00627264, 0.00626276, 0.0062528 ,\n",
       "        0.00624297, 0.00623353, 0.00622483, 0.0062174 , 0.00621197,\n",
       "        0.00620973, 0.00621253, 0.00622359, 0.00625005, 0.0062676 ])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 1020\n",
       "      nit: 20\n",
       "     njev: 20\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.40291306, 0.25180698, 0.192686  , 0.15826672, 0.13606309,\n",
       "        0.12092956, 0.11025676, 0.10255465, 0.0969049 , 0.09271058,\n",
       "        0.0895678 , 0.08719484, 0.0853899 , 0.08400532, 0.08293127,\n",
       "        0.0820848 , 0.08140292, 0.08083751, 0.08035203, 0.07991906,\n",
       "        0.07951843, 0.07913587, 0.07876197, 0.07839113, 0.07802114,\n",
       "        0.07765217, 0.07728667, 0.07692881, 0.07658406, 0.07625905,\n",
       "        0.07596153, 0.07570007, 0.07548411, 0.07532426, 0.07523242,\n",
       "        0.07522216, 0.07530958, 0.0755142 , 0.07586072, 0.07638141,\n",
       "        0.07712011, 0.07813848, 0.07952692, 0.08142317, 0.08404801,\n",
       "        0.08777738, 0.09330749, 0.10209948, 0.11791545, 0.16533602]),\n",
       " (0.7500000000000002,\n",
       "  0.55):      fun: 0.018985594022738264\n",
       "      jac: array([0.00640094, 0.00668578, 0.00672244, 0.00671776, 0.00669901,\n",
       "        0.00667599, 0.00665286, 0.00663151, 0.00661279, 0.00659703,\n",
       "        0.00658428, 0.00657445, 0.00656737, 0.00656282, 0.00656057,\n",
       "        0.00656038, 0.00656203, 0.00656526, 0.00656987, 0.00657563,\n",
       "        0.00658234, 0.0065898 , 0.00659784, 0.00660627, 0.00661494,\n",
       "        0.00662369, 0.0066324 , 0.00664092, 0.00664915, 0.00665698,\n",
       "        0.00666433, 0.00667112, 0.00667729, 0.00668282, 0.00668766,\n",
       "        0.00669183, 0.00669536, 0.00669828, 0.00670069, 0.00670272,\n",
       "        0.00670454, 0.00670638, 0.00670853, 0.00671137, 0.00671537,\n",
       "        0.00672108, 0.00672907, 0.00673962, 0.00675157, 0.00671592])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 561\n",
       "      nit: 11\n",
       "     njev: 11\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.26666519, 0.2011118 , 0.17042466, 0.15018565, 0.13551498,\n",
       "        0.12434518, 0.11558457, 0.10857979, 0.10290622, 0.09827139,\n",
       "        0.09446485, 0.09132986, 0.0887465 , 0.08662102, 0.08487871,\n",
       "        0.08345912, 0.08231276, 0.0813986 , 0.08068248, 0.08013554,\n",
       "        0.07973349, 0.07945568, 0.0792846 , 0.07920543, 0.0792056 ,\n",
       "        0.07927468, 0.07940411, 0.079587  , 0.07981819, 0.08009411,\n",
       "        0.08041285, 0.08077433, 0.08118026, 0.08163461, 0.08214382,\n",
       "        0.0827173 , 0.0833683 , 0.08411467, 0.08498054, 0.08599818,\n",
       "        0.08721128, 0.08867956, 0.09048664, 0.09275282, 0.09565832,\n",
       "        0.09948857, 0.10473356, 0.11234586, 0.12463002, 0.15400675]),\n",
       " (0.8000000000000003,\n",
       "  0.45):      fun: 0.015617696776047924\n",
       "      jac: array([0.00528014, 0.00565242, 0.00572653, 0.0057356 , 0.00571928,\n",
       "        0.00569288, 0.00566342, 0.00563439, 0.00560753, 0.00558366,\n",
       "        0.00556312, 0.00554595, 0.00553205, 0.00552123, 0.0055133 ,\n",
       "        0.00550804, 0.00550522, 0.00550462, 0.00550605, 0.00550928,\n",
       "        0.00551412, 0.00552038, 0.00552785, 0.00553634, 0.00554567,\n",
       "        0.00555567, 0.00556615, 0.00557698, 0.005588  , 0.00559908,\n",
       "        0.00561011, 0.00562098, 0.00563161, 0.00564194, 0.00565194,\n",
       "        0.00566159, 0.00567089, 0.00567991, 0.00568871, 0.00569741,\n",
       "        0.00570619, 0.00571523, 0.0057248 , 0.00573516, 0.00574658,\n",
       "        0.0057592 , 0.00577273, 0.00578546, 0.0057907 , 0.00571823])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 715\n",
       "      nit: 14\n",
       "     njev: 14\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.35786361, 0.25943428, 0.20989842, 0.1766358 , 0.15236728,\n",
       "        0.13389003, 0.11946519, 0.10802889, 0.09887727, 0.09151804,\n",
       "        0.08559208, 0.08082892, 0.07701916, 0.07399751, 0.07163102,\n",
       "        0.06981134, 0.0684491 , 0.06746988, 0.06681154, 0.06642163,\n",
       "        0.066256  , 0.06627744, 0.06645446, 0.06676078, 0.06717442,\n",
       "        0.06767737, 0.06825505, 0.06889606, 0.0695919 , 0.07033702,\n",
       "        0.07112851, 0.07196643, 0.0728541 , 0.07379812, 0.07480942,\n",
       "        0.07590396, 0.077104  , 0.07843996, 0.07995287, 0.08169821,\n",
       "        0.08375091, 0.08621396, 0.08923088, 0.09300716, 0.09784803,\n",
       "        0.10423066, 0.11295964, 0.12556159, 0.14560897, 0.19024108]),\n",
       " (0.8000000000000003,\n",
       "  0.5):      fun: 0.016184075375833544\n",
       "      jac: array([0.00558245, 0.00586743, 0.00590651, 0.00590139, 0.00588115,\n",
       "        0.00585631, 0.0058314 , 0.00580845, 0.00578837, 0.0057715 ,\n",
       "        0.00575788, 0.00574741, 0.00573989, 0.00573506, 0.00573269,\n",
       "        0.00573252, 0.00573427, 0.00573771, 0.00574259, 0.00574868,\n",
       "        0.00575576, 0.00576362, 0.00577206, 0.0057809 , 0.00578997,\n",
       "        0.00579911, 0.00580818, 0.00581704, 0.00582559, 0.00583372,\n",
       "        0.00584135, 0.00584842, 0.00585489, 0.00586073, 0.00586595,\n",
       "        0.00587056, 0.00587463, 0.00587824, 0.00588152, 0.00588464,\n",
       "        0.00588781, 0.00589131, 0.00589546, 0.00590068, 0.0059074 ,\n",
       "        0.00591606, 0.00592691, 0.00593938, 0.00594964, 0.00589654])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 663\n",
       "      nit: 13\n",
       "     njev: 13\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.29030299, 0.21459412, 0.17823691, 0.15423407, 0.13690795,\n",
       "        0.12381292, 0.11364218, 0.10560647, 0.09918921, 0.0940324 ,\n",
       "        0.08987728, 0.08653027, 0.08384295, 0.08169881, 0.0800049 ,\n",
       "        0.07868599, 0.07768035, 0.076937  , 0.07641339, 0.07607376,\n",
       "        0.07588805, 0.07583089, 0.07588088, 0.07601998, 0.0762332 ,\n",
       "        0.07650814, 0.07683483, 0.07720553, 0.07761465, 0.07805874,\n",
       "        0.07853647, 0.07904885, 0.07959941, 0.08019457, 0.08084408,\n",
       "        0.08156185, 0.08236667, 0.08328396, 0.0843474 , 0.08560186,\n",
       "        0.08710756, 0.08894661, 0.09123301, 0.09412979, 0.09787946,\n",
       "        0.10286284, 0.10972687, 0.1197129 , 0.13577327, 0.17286376]),\n",
       " (0.8000000000000003,\n",
       "  0.55):      fun: 0.01702386838078075\n",
       "      jac: array([0.00566283, 0.0060306 , 0.00616911, 0.00624382, 0.00628603,\n",
       "        0.00630879, 0.00631888, 0.00632029, 0.00631559, 0.00630651,\n",
       "        0.00629429, 0.00627985, 0.00626387, 0.00624689, 0.00622933,\n",
       "        0.00621153, 0.00619377, 0.00617628, 0.00615924, 0.00614283,\n",
       "        0.00612718, 0.00611241, 0.00609863, 0.00608592, 0.00607437,\n",
       "        0.00606404, 0.00605501, 0.00604732, 0.00604103, 0.00603617,\n",
       "        0.00603279, 0.00603091, 0.00603057, 0.00603177, 0.00603452,\n",
       "        0.00603882, 0.00604466, 0.00605198, 0.00606074, 0.00607082,\n",
       "        0.00608207, 0.00609427, 0.00610707, 0.00611993, 0.00613199,\n",
       "        0.00614183, 0.00614685, 0.00614176, 0.00611317, 0.00597922])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 306\n",
       "      nit: 6\n",
       "     njev: 6\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.19058388, 0.16741253, 0.15421928, 0.14437725, 0.13642368,\n",
       "        0.12972399, 0.12393541, 0.11884844, 0.11432448, 0.1102664 ,\n",
       "        0.10660332, 0.10328173, 0.10026027, 0.09750633, 0.09499375,\n",
       "        0.0927013 , 0.09061164, 0.08871044, 0.08698586, 0.08542812,\n",
       "        0.08402915, 0.08278237, 0.08168244, 0.08072524, 0.07990767,\n",
       "        0.07922758, 0.07868378, 0.07827601, 0.07800489, 0.07787204,\n",
       "        0.07788005, 0.07803269, 0.07833484, 0.07879293, 0.07941495,\n",
       "        0.08021088, 0.0811931 , 0.08237699, 0.08378179, 0.08543169,\n",
       "        0.08735764, 0.08959986, 0.09221195, 0.09526757, 0.0988721 ,\n",
       "        0.1031851 , 0.10846803, 0.1152053 , 0.12451454, 0.14147872]),\n",
       " (0.8500000000000003,\n",
       "  0.45):      fun: 0.01403841545535159\n",
       "      jac: array([0.00493893, 0.00520222, 0.00524249, 0.00523969, 0.00522212,\n",
       "        0.00520011, 0.00517809, 0.00515807, 0.00514092, 0.00512693,\n",
       "        0.00511612, 0.00510836, 0.00510342, 0.00510108, 0.00510105,\n",
       "        0.00510308, 0.0051069 , 0.00511227, 0.00511892, 0.00512663,\n",
       "        0.00513517, 0.00514432, 0.00515387, 0.00516365, 0.00517347,\n",
       "        0.00518318, 0.00519264, 0.00520172, 0.00521031, 0.00521832,\n",
       "        0.00522569, 0.00523237, 0.00523833, 0.00524358, 0.00524813,\n",
       "        0.00525205, 0.00525543, 0.00525838, 0.00526108, 0.00526371,\n",
       "        0.00526654, 0.00526985, 0.00527399, 0.00527932, 0.0052862 ,\n",
       "        0.00529484, 0.00530503, 0.00531509, 0.00531827, 0.00524526])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 664\n",
       "      nit: 13\n",
       "     njev: 13\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.30225295, 0.22161972, 0.18174401, 0.15531047, 0.13625657,\n",
       "        0.12192315, 0.11087042, 0.10221985, 0.09539164, 0.08998135,\n",
       "        0.08569477, 0.08231104, 0.07965998, 0.07760773, 0.07604731,\n",
       "        0.07489199, 0.07407071, 0.07352473, 0.07320524, 0.07307141,\n",
       "        0.07308902, 0.07322944, 0.07346876, 0.07378711, 0.07416811,\n",
       "        0.07459869, 0.07506854, 0.07557012, 0.07609849, 0.07665132,\n",
       "        0.077229  , 0.07783472, 0.07847498, 0.07915991, 0.07990403,\n",
       "        0.08072716, 0.08165572, 0.08272454, 0.08397938, 0.08548058,\n",
       "        0.08730838, 0.08957105, 0.09241766, 0.09605939, 0.10080705,\n",
       "        0.10714297, 0.11587557, 0.12853024, 0.14865944, 0.19307357]),\n",
       " (0.8500000000000003,\n",
       "  0.5):      fun: 0.014530378693834636\n",
       "      jac: array([0.00496477, 0.00529106, 0.00541923, 0.00548874, 0.00552779,\n",
       "        0.00554839, 0.00555688, 0.00555706, 0.00555137, 0.00554151,\n",
       "        0.00552868, 0.00551377, 0.00549746, 0.00548029, 0.00546267,\n",
       "        0.00544495, 0.0054274 , 0.00541024, 0.00539368, 0.00537788,\n",
       "        0.00536296, 0.00534904, 0.00533624, 0.00532462, 0.00531428,\n",
       "        0.00530526, 0.00529764, 0.00529146, 0.00528675, 0.00528354,\n",
       "        0.00528188, 0.00528176, 0.0052832 , 0.00528619, 0.00529072,\n",
       "        0.00529676, 0.00530426, 0.00531314, 0.00532328, 0.00533454,\n",
       "        0.00534668, 0.00535939, 0.0053722 , 0.00538441, 0.00539497,\n",
       "        0.00540214, 0.00540291, 0.0053913 , 0.00535269, 0.00520741])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 306\n",
       "      nit: 6\n",
       "     njev: 6\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.19645791, 0.17251214, 0.15835404, 0.14764031, 0.13890582,\n",
       "        0.13150427, 0.12508242, 0.11942249, 0.11437924, 0.10985031,\n",
       "        0.10576052, 0.10205297, 0.09868344, 0.09561694, 0.09282537,\n",
       "        0.0902859 , 0.08797977, 0.08589157, 0.0840085 , 0.08232006,\n",
       "        0.08081756, 0.07949396, 0.07834364, 0.07736224, 0.07654659,\n",
       "        0.0758946 , 0.07540526, 0.07507855, 0.07491557, 0.07491843,\n",
       "        0.07509048, 0.07543629, 0.07596187, 0.07667484, 0.07758471,\n",
       "        0.07870329, 0.08004508, 0.08162805, 0.08347451, 0.08561243,\n",
       "        0.08807742, 0.09091547, 0.0941876 , 0.09797706, 0.10240227,\n",
       "        0.10764098, 0.11398181, 0.12195309, 0.13275329, 0.15158905]),\n",
       " (0.8500000000000003,\n",
       "  0.55):      fun: 0.015212740624060118\n",
       "      jac: array([0.00527017, 0.00556468, 0.00567134, 0.00572676, 0.00575644,\n",
       "        0.00577093, 0.00577569, 0.00577392, 0.00576765, 0.00575826,\n",
       "        0.00574672, 0.00573372, 0.00571982, 0.00570541, 0.00569083,\n",
       "        0.00567632, 0.00566209, 0.00564831, 0.00563513, 0.00562266,\n",
       "        0.005611  , 0.00560023, 0.00559043, 0.00558166, 0.00557398,\n",
       "        0.00556742, 0.00556203, 0.00555784, 0.00555489, 0.00555318,\n",
       "        0.00555275, 0.00555359, 0.00555572, 0.00555913, 0.0055638 ,\n",
       "        0.0055697 , 0.00557681, 0.00558505, 0.00559433, 0.00560452,\n",
       "        0.00561545, 0.00562683, 0.00563828, 0.00564922, 0.00565872,\n",
       "        0.00566528, 0.00566621, 0.00565608, 0.00562124, 0.00548085])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 306\n",
       "      nit: 6\n",
       "     njev: 6\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.17601827, 0.15580406, 0.14433639, 0.13580682, 0.12893332,\n",
       "        0.12315984, 0.11818605, 0.11382853, 0.10996587, 0.10651308,\n",
       "        0.10340812, 0.10060421, 0.09806523, 0.09576265, 0.09367368,\n",
       "        0.09177985, 0.09006605, 0.08851985, 0.08713103, 0.08589115,\n",
       "        0.08479328, 0.08383183, 0.08300232, 0.08230132, 0.0817263 ,\n",
       "        0.08127565, 0.08094857, 0.08074512, 0.08066618, 0.08071351,\n",
       "        0.08088981, 0.08119879, 0.08164533, 0.0822356 , 0.08297732,\n",
       "        0.08388005, 0.08495562, 0.08621864, 0.08768737, 0.08938474,\n",
       "        0.09134002, 0.09359123, 0.096189  , 0.09920283, 0.10273217,\n",
       "        0.10692749, 0.11203536, 0.11851258, 0.127413  , 0.14352492]),\n",
       " (0.9000000000000004,\n",
       "  0.45):      fun: 0.012610762085734225\n",
       "      jac: array([0.0044525 , 0.00472274, 0.00483257, 0.00489212, 0.00492512,\n",
       "        0.00494189, 0.00494796, 0.00494668, 0.00494024, 0.00493016,\n",
       "        0.00491754, 0.00490318, 0.00488772, 0.00487163, 0.00485531,\n",
       "        0.00483907, 0.00482315, 0.00480778, 0.00479311, 0.00477931,\n",
       "        0.00476649, 0.00475476, 0.0047442 , 0.00473488, 0.00472687,\n",
       "        0.00472022, 0.00471498, 0.00471117, 0.00470882, 0.00470794,\n",
       "        0.00470855, 0.00471063, 0.00471419, 0.00471918, 0.00472556,\n",
       "        0.00473328, 0.00474225, 0.00475235, 0.00476341, 0.00477523,\n",
       "        0.0047875 , 0.00479983, 0.00481164, 0.00482211, 0.00483003,\n",
       "        0.00483344, 0.00482906, 0.00481057, 0.00476303, 0.00461285])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 306\n",
       "      nit: 6\n",
       "     njev: 6\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.19732838, 0.17360569, 0.15908887, 0.14795951, 0.1388147 ,\n",
       "        0.13102549, 0.12424424, 0.11825468, 0.11291156, 0.10811184,\n",
       "        0.10377954, 0.09985679, 0.09629852, 0.09306896, 0.09013928,\n",
       "        0.08748603, 0.08508997, 0.08293519, 0.0810086 , 0.07929938,\n",
       "        0.07779868, 0.07649934, 0.0753957 , 0.07448345, 0.07375953,\n",
       "        0.07322204, 0.07287022, 0.07270446, 0.07272627, 0.07293835,\n",
       "        0.07334466, 0.07395059, 0.07476304, 0.07579073, 0.07704441,\n",
       "        0.07853732, 0.08028573, 0.08230958, 0.08463359, 0.08728855,\n",
       "        0.09031349, 0.09375858, 0.09768996, 0.10219741, 0.10740771,\n",
       "        0.11350969, 0.12080718, 0.1298498 , 0.14186389, 0.16194883]),\n",
       " (0.9000000000000004,\n",
       "  0.5):      fun: 0.012986995895913768\n",
       "      jac: array([0.00462219, 0.00487915, 0.00497608, 0.00502654, 0.00505325,\n",
       "        0.00506579, 0.0050692 , 0.00506647, 0.00505954, 0.0050497 ,\n",
       "        0.00503789, 0.00502481, 0.00501096, 0.00499675, 0.00498249,\n",
       "        0.00496844, 0.00495479, 0.00494172, 0.00492935, 0.00491781,\n",
       "        0.00490719, 0.00489756, 0.004889  , 0.00488157, 0.00487531,\n",
       "        0.00487025, 0.00486644, 0.00486389, 0.00486262, 0.00486265,\n",
       "        0.00486398, 0.00486659, 0.00487049, 0.00487564, 0.004882  ,\n",
       "        0.00488952, 0.00489813, 0.00490772, 0.00491816, 0.00492926,\n",
       "        0.00494075, 0.00495229, 0.00496337, 0.00497325, 0.00498082,\n",
       "        0.00498428, 0.00498054, 0.00496354, 0.00491857, 0.00476733])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 306\n",
       "      nit: 6\n",
       "     njev: 6\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.1795719 , 0.15887303, 0.14668793, 0.13749909, 0.13003247,\n",
       "        0.12372621, 0.1182733 , 0.11348453, 0.10923372, 0.105432  ,\n",
       "        0.10201415, 0.09893075, 0.09614352, 0.09362215, 0.09134234,\n",
       "        0.08928434, 0.08743201, 0.08577207, 0.08429359, 0.08298755,\n",
       "        0.08184661, 0.08086484, 0.08003754, 0.07936116, 0.07883319,\n",
       "        0.07845209, 0.07821725, 0.07812902, 0.07818869, 0.07839852,\n",
       "        0.07876187, 0.07928324, 0.07996844, 0.08082478, 0.08186131,\n",
       "        0.08308918, 0.0845221 , 0.08617696, 0.0880747 , 0.09024153,\n",
       "        0.09271076, 0.09552543, 0.09874251, 0.10243976, 0.10672772,\n",
       "        0.11177229, 0.11784277, 0.12543222, 0.13565905, 0.1533778 ]),\n",
       " (0.9000000000000004,\n",
       "  0.55):      fun: 0.013583336131571297\n",
       "      jac: array([0.0048871 , 0.00512128, 0.00520259, 0.00524306, 0.0052633 ,\n",
       "        0.0052718 , 0.00527292, 0.0052692 , 0.00526223, 0.00525309,\n",
       "        0.00524254, 0.00523112, 0.00521924, 0.0052072 , 0.00519527,\n",
       "        0.00518361, 0.00517238, 0.00516172, 0.00515171, 0.00514245,\n",
       "        0.005134  , 0.00512641, 0.00511974, 0.00511403, 0.00510932,\n",
       "        0.00510562, 0.00510296, 0.00510135, 0.00510082, 0.00510136,\n",
       "        0.00510298, 0.00510568, 0.00510943, 0.00511424, 0.00512005,\n",
       "        0.00512684, 0.00513454, 0.00514307, 0.00515233, 0.00516216,\n",
       "        0.00517236, 0.00518263, 0.00519256, 0.00520153, 0.00520858,\n",
       "        0.00521216, 0.00520954, 0.00519523, 0.00515557, 0.00501143])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 306\n",
       "      nit: 6\n",
       "     njev: 6\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.16390699, 0.14619773, 0.13618777, 0.12876479, 0.12280039,\n",
       "        0.11780528, 0.11351522, 0.10976887, 0.10645949, 0.10351235,\n",
       "        0.10087292, 0.09850014, 0.09636227, 0.09443432, 0.09269632,\n",
       "        0.09113209, 0.08972846, 0.08847459, 0.08736161, 0.08638218,\n",
       "        0.0855304 , 0.08480143, 0.08419152, 0.08369783, 0.0833183 ,\n",
       "        0.08305174, 0.08289767, 0.0828564 , 0.08292898, 0.08311728,\n",
       "        0.08342405, 0.08385295, 0.08440874, 0.08509739, 0.08592631,\n",
       "        0.08690464, 0.08804365, 0.08935722, 0.09086267, 0.09258171,\n",
       "        0.09454202, 0.09677953, 0.09934203, 0.10229513, 0.10573265,\n",
       "        0.10979653, 0.11471931, 0.12093178, 0.1294278 , 0.14471857]),\n",
       " (0.9500000000000004,\n",
       "  0.45):      fun: 0.011269806684363021\n",
       "      jac: array([0.00414175, 0.00434919, 0.00442987, 0.00447163, 0.00449317,\n",
       "        0.00450257, 0.00450413, 0.00450045, 0.00449319, 0.00448353,\n",
       "        0.00447229, 0.00446007, 0.00444734, 0.00443447, 0.00442172,\n",
       "        0.00440932, 0.00439747, 0.00438629, 0.00437593, 0.00436646,\n",
       "        0.00435798, 0.00435056, 0.00434424, 0.00433907, 0.00433509,\n",
       "        0.00433232, 0.00433077, 0.00433047, 0.00433142, 0.0043336 ,\n",
       "        0.004337  , 0.0043416 , 0.00434736, 0.00435423, 0.00436215,\n",
       "        0.00437104, 0.00438077, 0.00439122, 0.00440218, 0.00441343,\n",
       "        0.00442463, 0.00443535, 0.00444499, 0.0044527 , 0.0044572 ,\n",
       "        0.00445653, 0.00444735, 0.00442334, 0.00436961, 0.0042144 ])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 306\n",
       "      nit: 6\n",
       "     njev: 6\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.17836351, 0.15812861, 0.14581061, 0.13640576, 0.12870816,\n",
       "        0.12217737, 0.11651473, 0.11153452, 0.10711201, 0.1031588 ,\n",
       "        0.09960967, 0.09641504, 0.09353629, 0.09094283, 0.08861001,\n",
       "        0.08651783, 0.08464987, 0.08299265, 0.08153508, 0.08026804,\n",
       "        0.07918413, 0.07827739, 0.07754319, 0.07697809, 0.07657969,\n",
       "        0.0763467 , 0.07627877, 0.07637657, 0.07664182, 0.07707727,\n",
       "        0.07768684, 0.07847569, 0.07945041, 0.08061919, 0.08199214,\n",
       "        0.08358159, 0.08540264, 0.08747381, 0.08981796, 0.09246354,\n",
       "        0.09544656, 0.0988133 , 0.1026247 , 0.10696346, 0.11194628,\n",
       "        0.11774707, 0.12464549, 0.13314764, 0.14438294, 0.16304375]),\n",
       " (0.9500000000000004,\n",
       "  0.5):      fun: 0.011596329215883033\n",
       "      jac: array([0.00428655, 0.00448702, 0.0045593 , 0.00459513, 0.00461262,\n",
       "        0.00461937, 0.00461934, 0.00461488, 0.00460748, 0.00459815,\n",
       "        0.00458759, 0.00457634, 0.00456478, 0.0045532 , 0.00454184,\n",
       "        0.00453089, 0.00452048, 0.00451074, 0.00450176, 0.00449362,\n",
       "        0.00448638, 0.00448009, 0.00447481, 0.00447055, 0.00446735,\n",
       "        0.00446522, 0.00446419, 0.00446425, 0.0044654 , 0.00446765,\n",
       "        0.00447098, 0.00447537, 0.00448079, 0.0044872 , 0.00449455,\n",
       "        0.00450277, 0.00451176, 0.0045214 , 0.00453155, 0.00454198,\n",
       "        0.00455244, 0.00456253, 0.00457173, 0.00457929, 0.00458405,\n",
       "        0.0045842 , 0.00457663, 0.00455528, 0.00450556, 0.00435125])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 306\n",
       "      nit: 6\n",
       "     njev: 6\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.16570251, 0.14772918, 0.13719524, 0.12927979, 0.12286991,\n",
       "        0.11747494, 0.11282683, 0.1087604 , 0.10516556, 0.10196478,\n",
       "        0.09910117, 0.09653171, 0.09422302, 0.09214873, 0.09028775,\n",
       "        0.08862292, 0.08714028, 0.08582834, 0.08467769, 0.0836806 ,\n",
       "        0.08283081, 0.0821233 , 0.08155416, 0.08112048, 0.08082029,\n",
       "        0.08065247, 0.08061675, 0.08071374, 0.08094485, 0.08131246,\n",
       "        0.08181989, 0.08247151, 0.08327293, 0.08423113, 0.08535469,\n",
       "        0.08665417, 0.08814248, 0.08983549, 0.09175286, 0.09391917,\n",
       "        0.09636557, 0.09913234, 0.10227273, 0.1058594 , 0.10999558,\n",
       "        0.11483622, 0.12063283, 0.12784585, 0.13751983, 0.15418464]),\n",
       " (0.9500000000000004,\n",
       "  0.55):      fun: 0.012121024271324138\n",
       "      jac: array([0.00451808, 0.00470305, 0.00476436, 0.00479334, 0.00480655,\n",
       "        0.00481078, 0.00480949, 0.00480466, 0.00479755, 0.004789  ,\n",
       "        0.00477958, 0.00476972, 0.00475971, 0.0047498 , 0.00474016,\n",
       "        0.00473092, 0.00472221, 0.00471411, 0.00470669, 0.0047    ,\n",
       "        0.00469409, 0.00468901, 0.00468477, 0.0046814 , 0.00467893,\n",
       "        0.00467736, 0.00467671, 0.00467698, 0.00467816, 0.00468027,\n",
       "        0.00468327, 0.00468718, 0.00469195, 0.00469756, 0.00470398,\n",
       "        0.00471114, 0.00471898, 0.0047274 , 0.00473629, 0.00474548,\n",
       "        0.00475475, 0.00476379, 0.00477217, 0.00477925, 0.00478406,\n",
       "        0.00478503, 0.00477942, 0.00476177, 0.00471856, 0.00457295])\n",
       "  message: 'Optimization terminated successfully'\n",
       "     nfev: 306\n",
       "      nit: 6\n",
       "     njev: 6\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.1538392 , 0.13824831, 0.12946818, 0.1229772 , 0.11777733,\n",
       "        0.11343587, 0.10971922, 0.10648474, 0.1036381 , 0.10111329,\n",
       "        0.09886212, 0.09684836, 0.09504402, 0.09342707, 0.09197991,\n",
       "        0.09068834, 0.08954076, 0.08852772, 0.08764144, 0.08687557,\n",
       "        0.08622498, 0.08568556, 0.0852541 , 0.08492823, 0.08470633,\n",
       "        0.08458751, 0.08457155, 0.08465896, 0.08485091, 0.08514936,\n",
       "        0.08555703, 0.08607755, 0.08671553, 0.08747672, 0.08836824,\n",
       "        0.08939881, 0.09057916, 0.09192252, 0.09344525, 0.09516796,\n",
       "        0.09711684, 0.09932585, 0.10184019, 0.10472181, 0.10805934,\n",
       "        0.11198678, 0.11672368, 0.12267678, 0.13078437, 0.14530135])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(result_vwap.x.astype(np.float)/N).plot()\n",
    "pd.Series(result_gss.x.astype(np.float)/N).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sqp_record.pickle', 'wb') as handle:\n",
    "    pickle.dump(sqp_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b07a4c983e57ffd979b6a111ad73892f909c14a0d47f7604a41c52f9ad946a6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
